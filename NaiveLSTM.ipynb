{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc453bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Re-loads all imports every time the cell is ran. \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Sklearn tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8146577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeseriesDataset(Dataset):   \n",
    "    '''\n",
    "    Custom Dataset subclass. \n",
    "    Serves as input to DataLoader to transform X \n",
    "      into sequence data using rolling window. \n",
    "    DataLoader using this dataset will output batches \n",
    "      of `(batch_size, seq_len, n_features)` shape.\n",
    "    Suitable as an input to RNNs. \n",
    "    '''\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 1):\n",
    "        self.X = torch.tensor(X).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - (self.seq_len-1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5d5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleAcceleratorDataModule(pl.LightningDataModule):\n",
    "    '''\n",
    "    PyTorch Lighting DataModule subclass:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html\n",
    "\n",
    "    Serves the purpose of aggregating all data loading \n",
    "      and processing work in one place.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seq_len = 1, batch_size = 128, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        self.X_test = None\n",
    "        self.X_test = None\n",
    "        self.columns = None\n",
    "        self.preprocessing = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):        \n",
    "        \n",
    "        df = pd.read_pickle('pickled_df_ALL.pk').diff()\n",
    "\n",
    "\n",
    "        X = df[['Fwd1Amp',  'Fwd2Amp', 'CavAmp', 'SpareAmp', 'LP_Amp','RevAmp','Fwd1Phs', 'Fwd2Phs', 'Cavphs', 'SparePhs',  'LP_Phase', 'Rev_Phs']]\n",
    "        y = df['SCam3_Gauss_yCentroid']\n",
    "        \n",
    "        X = X.dropna()\n",
    "        y = y.dropna()\n",
    "        self.columns = X.columns\n",
    "\n",
    "\n",
    "        X_cv, X_test, y_cv, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=False\n",
    "        )\n",
    "    \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_cv, y_cv, test_size=0.25, shuffle=False\n",
    "        )\n",
    "\n",
    "        preprocessing = RobustScaler()\n",
    "        preprocessing.fit(X_train)\n",
    "\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.X_train = preprocessing.transform(X_train)\n",
    "            self.y_train = y_train.values.reshape((-1, 1))\n",
    "            self.X_val = preprocessing.transform(X_val)\n",
    "            self.y_val = y_val.values.reshape((-1, 1))\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.X_test = preprocessing.transform(X_test)\n",
    "            self.y_test = y_test.values.reshape((-1, 1))\n",
    "        \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = TimeseriesDataset(self.X_train, \n",
    "                                          self.y_train, \n",
    "                                          seq_len=self.seq_len)\n",
    "        train_loader = DataLoader(train_dataset, \n",
    "                                  batch_size = self.batch_size, \n",
    "                                  shuffle = False, \n",
    "                                  num_workers = self.num_workers)\n",
    "        \n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = TimeseriesDataset(self.X_val, \n",
    "                                        self.y_val, \n",
    "                                        seq_len=self.seq_len)\n",
    "        val_loader = DataLoader(val_dataset, \n",
    "                                batch_size = self.batch_size, \n",
    "                                shuffle = False, \n",
    "                                num_workers = self.num_workers)\n",
    "\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = TimeseriesDataset(self.X_test, \n",
    "                                         self.y_test, \n",
    "                                         seq_len=self.seq_len)\n",
    "        test_loader = DataLoader(test_dataset, \n",
    "                                 batch_size = self.batch_size, \n",
    "                                 shuffle = False, \n",
    "                                 num_workers = self.num_workers)\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db54d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(pl.LightningModule):\n",
    "    '''\n",
    "    Standard PyTorch Lightning module:\n",
    "    https://pytorch-lightning.readthedocs.io/en/latest/lightning_module.html\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 n_features, \n",
    "                 hidden_size, \n",
    "                 seq_len, \n",
    "                 batch_size,\n",
    "                 num_layers, \n",
    "                 dropout, \n",
    "                 learning_rate,\n",
    "                 criterion):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=n_features, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, \n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # lstm_out = (batch_size, seq_len, hidden_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        y_pred = self.linear(lstm_out[:,-1])\n",
    "        return y_pred\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        result = self.criterion(y_hat, y)\n",
    "        return result\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        result= self.criterion(y_hat, y)\n",
    "        return result\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        result = self.criterion(y_hat, y)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All parameters are aggregated in one place.\n",
    "This is useful for reporting experiment params to experiment tracking software\n",
    "'''\n",
    "\n",
    "p = dict(\n",
    "    seq_len = 24,\n",
    "    batch_size = 70, \n",
    "    criterion = nn.MSELoss(),\n",
    "    max_epochs = 100,\n",
    "    n_features = 12,\n",
    "    hidden_size =24,\n",
    "    num_layers = 1,\n",
    "    dropout = 0.2,\n",
    "    learning_rate = 0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c8f5b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=2)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/loggers/csv_logs.py:57: UserWarning: Experiment logs directory ./lstm/0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | criterion | MSELoss | 0     \n",
      "1 | lstm      | LSTM    | 3.6 K \n",
      "2 | linear    | Linear  | 25    \n",
      "--------------------------------------\n",
      "3.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.7 K     Total params\n",
      "0.015     Total estimated model params size (MB)\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /Users/lauren/marinetti/lstm/0/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 1\n",
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|█████████▊   | 96/128 [00:00<00:00, 96.37it/s, loss=43.9, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  88%|█████████▋ | 112/128 [00:01<00:00, 103.59it/s, loss=43.9, v_num=0]\u001b[A\n",
      "Epoch 0: 100%|███████████| 128/128 [00:01<00:00, 109.00it/s, loss=43.9, v_num=0]\u001b[A\n",
      "Epoch 1:  75%|█████████▊   | 96/128 [00:01<00:00, 86.23it/s, loss=43.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|██████████▏ | 108/128 [00:01<00:00, 91.96it/s, loss=43.9, v_num=0]\u001b[A\n",
      "Epoch 1: 100%|███████████| 128/128 [00:01<00:00, 100.75it/s, loss=43.9, v_num=0]\u001b[A\n",
      "Epoch 2:  75%|█████████▊   | 96/128 [00:01<00:00, 88.76it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  84%|██████████▏ | 108/128 [00:01<00:00, 95.60it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 2: 100%|███████████| 128/128 [00:01<00:00, 100.93it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 3:  75%|█████████▊   | 96/128 [00:01<00:00, 87.89it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  84%|██████████▏ | 108/128 [00:01<00:00, 94.49it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 3: 100%|███████████| 128/128 [00:01<00:00, 102.40it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 4:  75%|█████████▊   | 96/128 [00:01<00:00, 50.01it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  84%|██████████▏ | 108/128 [00:01<00:00, 54.72it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 4: 100%|████████████| 128/128 [00:02<00:00, 61.14it/s, loss=43.8, v_num=0]\u001b[A\n",
      "Epoch 5:  75%|█████████▊   | 96/128 [00:01<00:00, 82.10it/s, loss=43.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  78%|█████████▍  | 100/128 [00:01<00:00, 84.37it/s, loss=43.7, v_num=0]\u001b[A\n",
      "Epoch 5: 100%|████████████| 128/128 [00:01<00:00, 96.55it/s, loss=43.7, v_num=0]\u001b[A\n",
      "Epoch 6:  75%|█████████▊   | 96/128 [00:01<00:00, 90.31it/s, loss=43.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  86%|██████████▎ | 110/128 [00:01<00:00, 96.19it/s, loss=43.6, v_num=0]\u001b[A\n",
      "Epoch 6: 100%|███████████| 128/128 [00:01<00:00, 102.24it/s, loss=43.6, v_num=0]\u001b[A\n",
      "Epoch 7:  75%|█████████▊   | 96/128 [00:01<00:00, 75.09it/s, loss=43.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  86%|██████████▎ | 110/128 [00:01<00:00, 82.19it/s, loss=43.3, v_num=0]\u001b[A\n",
      "Epoch 7: 100%|████████████| 128/128 [00:01<00:00, 88.06it/s, loss=43.3, v_num=0]\u001b[A\n",
      "Epoch 8:  75%|█████████▊   | 96/128 [00:02<00:00, 32.36it/s, loss=42.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  86%|██████████▎ | 110/128 [00:03<00:00, 35.42it/s, loss=42.5, v_num=0]\u001b[A\n",
      "Epoch 8: 100%|████████████| 128/128 [00:03<00:00, 39.64it/s, loss=42.5, v_num=0]\u001b[A\n",
      "Epoch 9:  75%|███████████▎   | 96/128 [00:04<00:01, 20.33it/s, loss=41, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  86%|████████████  | 110/128 [00:04<00:00, 22.97it/s, loss=41, v_num=0]\u001b[A\n",
      "Epoch 9: 100%|██████████████| 128/128 [00:04<00:00, 26.17it/s, loss=41, v_num=0]\u001b[A\n",
      "Epoch 10:  75%|█████████   | 96/128 [00:01<00:00, 82.61it/s, loss=40.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  86%|█████████▍ | 110/128 [00:01<00:00, 88.31it/s, loss=40.3, v_num=0]\u001b[A\n",
      "Epoch 10: 100%|███████████| 128/128 [00:01<00:00, 95.57it/s, loss=40.3, v_num=0]\u001b[A\n",
      "Epoch 11:  75%|█████████   | 96/128 [00:01<00:00, 78.68it/s, loss=40.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  86%|█████████▍ | 110/128 [00:01<00:00, 84.88it/s, loss=40.2, v_num=0]\u001b[A\n",
      "Epoch 11: 100%|███████████| 128/128 [00:01<00:00, 91.71it/s, loss=40.2, v_num=0]\u001b[A\n",
      "Epoch 12:  75%|█████████   | 96/128 [00:01<00:00, 63.02it/s, loss=39.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  86%|█████████▍ | 110/128 [00:01<00:00, 67.85it/s, loss=39.8, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 124.63it/s]\u001b[A\n",
      "Epoch 12: 100%|███████████| 128/128 [00:01<00:00, 73.13it/s, loss=39.8, v_num=0]\u001b[A\n",
      "Epoch 13:  75%|█████████   | 96/128 [00:01<00:00, 63.83it/s, loss=39.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  86%|█████████▍ | 110/128 [00:01<00:00, 67.97it/s, loss=39.6, v_num=0]\u001b[A\n",
      "Epoch 13: 100%|███████████| 128/128 [00:01<00:00, 73.56it/s, loss=39.6, v_num=0]\u001b[A\n",
      "Epoch 14:  75%|█████████   | 96/128 [00:02<00:00, 38.17it/s, loss=39.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  86%|█████████▍ | 110/128 [00:02<00:00, 40.82it/s, loss=39.5, v_num=0]\u001b[A\n",
      "Validating:  50%|███████████████▌               | 16/32 [00:00<00:00, 84.10it/s]\u001b[A\n",
      "Epoch 14: 100%|███████████| 128/128 [00:02<00:00, 44.92it/s, loss=39.5, v_num=0]\u001b[A\n",
      "Epoch 15:  75%|█████████   | 96/128 [00:01<00:00, 52.47it/s, loss=39.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   6%|██                              | 2/32 [00:00<00:01, 19.67it/s]\u001b[A\n",
      "Validating:  12%|████                            | 4/32 [00:00<00:02, 10.80it/s]\u001b[A\n",
      "Epoch 15:  86%|█████████▍ | 110/128 [00:02<00:00, 46.25it/s, loss=39.1, v_num=0]\u001b[A\n",
      "Validating:  56%|█████████████████▍             | 18/32 [00:00<00:00, 41.00it/s]\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 24/32 [00:00<00:00, 32.98it/s]\u001b[A\n",
      "Epoch 15: 100%|███████████| 128/128 [00:02<00:00, 45.39it/s, loss=39.1, v_num=0]\u001b[A\n",
      "Epoch 16:  75%|█████████   | 96/128 [00:01<00:00, 74.92it/s, loss=38.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 16:  86%|█████████▍ | 110/128 [00:01<00:00, 80.17it/s, loss=38.7, v_num=0]\u001b[A\n",
      "Epoch 16: 100%|███████████| 128/128 [00:01<00:00, 86.41it/s, loss=38.7, v_num=0]\u001b[A\n",
      "Epoch 17:  75%|█████████   | 96/128 [00:01<00:00, 75.22it/s, loss=38.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 17:  86%|█████████▍ | 110/128 [00:01<00:00, 81.14it/s, loss=38.4, v_num=0]\u001b[A\n",
      "Epoch 17: 100%|███████████| 128/128 [00:01<00:00, 87.95it/s, loss=38.4, v_num=0]\u001b[A\n",
      "Epoch 18:  75%|██████████▌   | 96/128 [00:01<00:00, 82.52it/s, loss=38, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 18:  86%|███████████▏ | 110/128 [00:01<00:00, 89.51it/s, loss=38, v_num=0]\u001b[A\n",
      "Epoch 18: 100%|█████████████| 128/128 [00:01<00:00, 91.63it/s, loss=38, v_num=0]\u001b[A\n",
      "Epoch 19:  75%|█████████   | 96/128 [00:01<00:00, 69.07it/s, loss=37.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 19:  86%|█████████▍ | 110/128 [00:01<00:00, 75.41it/s, loss=37.9, v_num=0]\u001b[A\n",
      "Epoch 19: 100%|███████████| 128/128 [00:01<00:00, 77.95it/s, loss=37.9, v_num=0]\u001b[A\n",
      "Epoch 20:  75%|█████████   | 96/128 [00:01<00:00, 71.45it/s, loss=37.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  86%|█████████▍ | 110/128 [00:01<00:00, 75.52it/s, loss=37.6, v_num=0]\u001b[A\n",
      "Epoch 20: 100%|███████████| 128/128 [00:01<00:00, 79.87it/s, loss=37.6, v_num=0]\u001b[A\n",
      "Epoch 21:  75%|█████████   | 96/128 [00:01<00:00, 62.73it/s, loss=39.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 21:  86%|█████████▍ | 110/128 [00:01<00:00, 67.35it/s, loss=39.3, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 121.50it/s]\u001b[A\n",
      "Epoch 21: 100%|███████████| 128/128 [00:01<00:00, 71.38it/s, loss=39.3, v_num=0]\u001b[A\n",
      "Epoch 22:  75%|█████████   | 96/128 [00:01<00:00, 56.55it/s, loss=37.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 22:  86%|█████████▍ | 110/128 [00:01<00:00, 61.70it/s, loss=37.5, v_num=0]\u001b[A\n",
      "Epoch 22: 100%|███████████| 128/128 [00:01<00:00, 67.55it/s, loss=37.5, v_num=0]\u001b[A\n",
      "Epoch 23:  75%|█████████   | 96/128 [00:01<00:00, 79.06it/s, loss=37.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 23:  86%|█████████▍ | 110/128 [00:01<00:00, 84.13it/s, loss=37.2, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 132.39it/s]\u001b[A\n",
      "Epoch 23: 100%|███████████| 128/128 [00:01<00:00, 86.86it/s, loss=37.2, v_num=0]\u001b[A\n",
      "Epoch 24:  75%|█████████   | 96/128 [00:01<00:00, 68.58it/s, loss=36.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 24:  86%|█████████▍ | 110/128 [00:01<00:00, 73.91it/s, loss=36.7, v_num=0]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 139.86it/s]\u001b[A\n",
      "Epoch 24: 100%|███████████| 128/128 [00:01<00:00, 78.25it/s, loss=36.7, v_num=0]\u001b[A\n",
      "Epoch 25:  75%|█████████   | 96/128 [00:01<00:00, 89.13it/s, loss=36.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 25:  86%|█████████▍ | 110/128 [00:01<00:00, 96.27it/s, loss=36.7, v_num=0]\u001b[A\n",
      "Epoch 25: 100%|██████████| 128/128 [00:01<00:00, 103.40it/s, loss=36.7, v_num=0]\u001b[A\n",
      "Epoch 26:  75%|█████████   | 96/128 [00:01<00:00, 72.99it/s, loss=36.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 26:  86%|█████████▍ | 110/128 [00:01<00:00, 79.70it/s, loss=36.4, v_num=0]\u001b[A\n",
      "Epoch 26: 100%|███████████| 128/128 [00:01<00:00, 84.92it/s, loss=36.4, v_num=0]\u001b[A\n",
      "Epoch 27:  75%|█████████   | 96/128 [00:01<00:00, 83.46it/s, loss=36.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 27:  86%|█████████▍ | 110/128 [00:01<00:00, 90.02it/s, loss=36.2, v_num=0]\u001b[A\n",
      "Epoch 27: 100%|███████████| 128/128 [00:01<00:00, 96.61it/s, loss=36.2, v_num=0]\u001b[A\n",
      "Epoch 28:  75%|█████████   | 96/128 [00:01<00:00, 76.20it/s, loss=35.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 28:  86%|█████████▍ | 110/128 [00:01<00:00, 81.67it/s, loss=35.5, v_num=0]\u001b[A\n",
      "Epoch 28: 100%|███████████| 128/128 [00:01<00:00, 87.50it/s, loss=35.5, v_num=0]\u001b[A\n",
      "Epoch 29:  75%|█████████   | 96/128 [00:01<00:00, 76.26it/s, loss=35.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 29:  86%|█████████▍ | 110/128 [00:01<00:00, 83.17it/s, loss=35.1, v_num=0]\u001b[A\n",
      "Epoch 29: 100%|███████████| 128/128 [00:01<00:00, 89.63it/s, loss=35.1, v_num=0]\u001b[A\n",
      "Epoch 30:  75%|█████████   | 96/128 [00:01<00:00, 85.69it/s, loss=34.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 30:  86%|█████████▍ | 110/128 [00:01<00:00, 91.83it/s, loss=34.6, v_num=0]\u001b[A\n",
      "Epoch 30: 100%|███████████| 128/128 [00:01<00:00, 96.61it/s, loss=34.6, v_num=0]\u001b[A\n",
      "Epoch 31:  75%|█████████   | 96/128 [00:01<00:00, 76.30it/s, loss=34.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 31:  86%|█████████▍ | 110/128 [00:01<00:00, 82.46it/s, loss=34.5, v_num=0]\u001b[A\n",
      "Epoch 31: 100%|███████████| 128/128 [00:01<00:00, 88.85it/s, loss=34.5, v_num=0]\u001b[A\n",
      "Epoch 32:  75%|█████████   | 96/128 [00:01<00:00, 77.13it/s, loss=33.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 32:  86%|█████████▍ | 110/128 [00:01<00:00, 83.00it/s, loss=33.6, v_num=0]\u001b[A\n",
      "Epoch 32: 100%|███████████| 128/128 [00:01<00:00, 89.81it/s, loss=33.6, v_num=0]\u001b[A\n",
      "Epoch 33:  75%|█████████   | 96/128 [00:01<00:00, 83.62it/s, loss=33.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 33:  86%|█████████▍ | 110/128 [00:01<00:00, 89.88it/s, loss=33.3, v_num=0]\u001b[A\n",
      "Epoch 33: 100%|███████████| 128/128 [00:01<00:00, 95.72it/s, loss=33.3, v_num=0]\u001b[A\n",
      "Epoch 34:  75%|█████████   | 96/128 [00:01<00:00, 81.66it/s, loss=33.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  86%|█████████▍ | 110/128 [00:01<00:00, 85.34it/s, loss=33.2, v_num=0]\u001b[A\n",
      "Epoch 34: 100%|███████████| 128/128 [00:01<00:00, 90.15it/s, loss=33.2, v_num=0]\u001b[A\n",
      "Epoch 35:  75%|█████████   | 96/128 [00:01<00:00, 63.76it/s, loss=32.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  86%|█████████▍ | 110/128 [00:01<00:00, 65.77it/s, loss=32.8, v_num=0]\u001b[A\n",
      "Validating:  62%|███████████████████▍           | 20/32 [00:00<00:00, 55.13it/s]\u001b[A\n",
      "Epoch 35: 100%|███████████| 128/128 [00:02<00:00, 63.15it/s, loss=32.8, v_num=0]\u001b[A\n",
      "Epoch 36:  75%|█████████   | 96/128 [00:01<00:00, 67.28it/s, loss=31.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  86%|█████████▍ | 110/128 [00:01<00:00, 70.73it/s, loss=31.9, v_num=0]\u001b[A\n",
      "Epoch 36: 100%|███████████| 128/128 [00:01<00:00, 76.61it/s, loss=31.9, v_num=0]\u001b[A\n",
      "Epoch 37:  75%|█████████   | 96/128 [00:01<00:00, 51.06it/s, loss=32.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  86%|█████████▍ | 110/128 [00:02<00:00, 51.37it/s, loss=32.1, v_num=0]\u001b[A\n",
      "Validating:  50%|███████████████▌               | 16/32 [00:00<00:00, 65.36it/s]\u001b[A\n",
      "Epoch 37: 100%|███████████| 128/128 [00:02<00:00, 56.21it/s, loss=32.1, v_num=0]\u001b[A\n",
      "Epoch 38:  75%|█████████   | 96/128 [00:01<00:00, 80.12it/s, loss=31.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 38:  86%|█████████▍ | 110/128 [00:01<00:00, 86.76it/s, loss=31.4, v_num=0]\u001b[A\n",
      "Epoch 38: 100%|███████████| 128/128 [00:01<00:00, 91.22it/s, loss=31.4, v_num=0]\u001b[A\n",
      "Epoch 39:  75%|█████████   | 96/128 [00:01<00:00, 80.02it/s, loss=31.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 39:  86%|█████████▍ | 110/128 [00:01<00:00, 86.04it/s, loss=31.5, v_num=0]\u001b[A\n",
      "Epoch 39: 100%|███████████| 128/128 [00:01<00:00, 90.92it/s, loss=31.5, v_num=0]\u001b[A\n",
      "Epoch 40:  75%|█████████   | 96/128 [00:01<00:00, 73.68it/s, loss=30.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 40:  86%|█████████▍ | 110/128 [00:01<00:00, 79.66it/s, loss=30.9, v_num=0]\u001b[A\n",
      "Epoch 40: 100%|███████████| 128/128 [00:01<00:00, 86.09it/s, loss=30.9, v_num=0]\u001b[A\n",
      "Epoch 41:  75%|█████████   | 96/128 [00:01<00:00, 69.98it/s, loss=30.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 41:  86%|█████████▍ | 110/128 [00:01<00:00, 76.62it/s, loss=30.1, v_num=0]\u001b[A\n",
      "Epoch 41: 100%|███████████| 128/128 [00:01<00:00, 83.03it/s, loss=30.1, v_num=0]\u001b[A\n",
      "Epoch 42:  75%|█████████   | 96/128 [00:01<00:00, 63.95it/s, loss=29.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 42:  86%|█████████▍ | 110/128 [00:01<00:00, 69.55it/s, loss=29.9, v_num=0]\u001b[A\n",
      "Epoch 42: 100%|███████████| 128/128 [00:01<00:00, 75.23it/s, loss=29.9, v_num=0]\u001b[A\n",
      "Epoch 43:  75%|█████████   | 96/128 [00:02<00:00, 44.62it/s, loss=29.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 43:  86%|█████████▍ | 110/128 [00:02<00:00, 49.49it/s, loss=29.5, v_num=0]\u001b[A\n",
      "Epoch 43: 100%|███████████| 128/128 [00:02<00:00, 54.60it/s, loss=29.5, v_num=0]\u001b[A\n",
      "Epoch 44:  75%|█████████   | 96/128 [00:01<00:00, 55.59it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 44:  86%|█████████▍ | 110/128 [00:01<00:00, 61.17it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Epoch 44: 100%|███████████| 128/128 [00:01<00:00, 67.18it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Epoch 45:  75%|█████████   | 96/128 [00:01<00:00, 90.33it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 45:  86%|█████████▍ | 110/128 [00:01<00:00, 96.94it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Epoch 45: 100%|██████████| 128/128 [00:01<00:00, 102.65it/s, loss=29.2, v_num=0]\u001b[A\n",
      "Epoch 46:  75%|█████████   | 96/128 [00:01<00:00, 67.12it/s, loss=28.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 46:  86%|█████████▍ | 110/128 [00:01<00:00, 73.45it/s, loss=28.6, v_num=0]\u001b[A\n",
      "Epoch 46: 100%|███████████| 128/128 [00:01<00:00, 78.30it/s, loss=28.6, v_num=0]\u001b[A\n",
      "Epoch 47:  75%|█████████   | 96/128 [00:01<00:00, 75.21it/s, loss=27.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 47:  86%|█████████▍ | 110/128 [00:01<00:00, 80.98it/s, loss=27.9, v_num=0]\u001b[A\n",
      "Validating:  50%|███████████████               | 16/32 [00:00<00:00, 157.87it/s]\u001b[A\n",
      "Epoch 47: 100%|███████████| 128/128 [00:01<00:00, 85.50it/s, loss=27.9, v_num=0]\u001b[A\n",
      "Epoch 48:  75%|█████████   | 96/128 [00:01<00:00, 80.05it/s, loss=27.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 48:  86%|█████████▍ | 110/128 [00:01<00:00, 84.88it/s, loss=27.5, v_num=0]\u001b[A\n",
      "Epoch 48: 100%|███████████| 128/128 [00:01<00:00, 90.89it/s, loss=27.5, v_num=0]\u001b[A\n",
      "Epoch 49:  75%|█████████   | 96/128 [00:01<00:00, 74.76it/s, loss=26.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 49:  86%|█████████▍ | 110/128 [00:01<00:00, 79.96it/s, loss=26.9, v_num=0]\u001b[A\n",
      "Epoch 49: 100%|███████████| 128/128 [00:01<00:00, 86.53it/s, loss=26.9, v_num=0]\u001b[A\n",
      "Epoch 50:  75%|█████████   | 96/128 [00:01<00:00, 76.73it/s, loss=27.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 50:  86%|█████████▍ | 110/128 [00:01<00:00, 83.55it/s, loss=27.2, v_num=0]\u001b[A\n",
      "Epoch 50: 100%|███████████| 128/128 [00:01<00:00, 87.91it/s, loss=27.2, v_num=0]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51:  75%|█████████   | 96/128 [00:01<00:00, 84.53it/s, loss=26.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 51:  86%|█████████▍ | 110/128 [00:01<00:00, 91.38it/s, loss=26.2, v_num=0]\u001b[A\n",
      "Epoch 51: 100%|███████████| 128/128 [00:01<00:00, 97.89it/s, loss=26.2, v_num=0]\u001b[A\n",
      "Epoch 52:  75%|█████████   | 96/128 [00:01<00:00, 89.58it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 52:  86%|█████████▍ | 110/128 [00:01<00:00, 96.24it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Epoch 52: 100%|██████████| 128/128 [00:01<00:00, 102.77it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Epoch 53:  75%|█████████   | 96/128 [00:01<00:00, 72.82it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 53:  86%|█████████▍ | 110/128 [00:01<00:00, 78.44it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Epoch 53: 100%|███████████| 128/128 [00:01<00:00, 85.41it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Epoch 54:  75%|█████████   | 96/128 [00:01<00:00, 68.86it/s, loss=25.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 54:  86%|█████████▍ | 110/128 [00:01<00:00, 74.45it/s, loss=25.6, v_num=0]\u001b[A\n",
      "Validating:  50%|███████████████               | 16/32 [00:00<00:00, 155.80it/s]\u001b[A\n",
      "Epoch 54: 100%|███████████| 128/128 [00:01<00:00, 76.05it/s, loss=25.6, v_num=0]\u001b[A\n",
      "Epoch 55:  75%|█████████   | 96/128 [00:02<00:00, 46.81it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 55:  86%|█████████▍ | 110/128 [00:02<00:00, 51.37it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 112.48it/s]\u001b[A\n",
      "Epoch 55: 100%|███████████| 128/128 [00:02<00:00, 55.29it/s, loss=26.1, v_num=0]\u001b[A\n",
      "Epoch 56:  75%|█████████   | 96/128 [00:01<00:00, 49.15it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 56:  86%|█████████▍ | 110/128 [00:02<00:00, 53.80it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 139.94it/s]\u001b[A\n",
      "Epoch 56: 100%|███████████| 128/128 [00:02<00:00, 55.90it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Epoch 57:  75%|█████████   | 96/128 [00:01<00:00, 56.81it/s, loss=25.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  86%|█████████▍ | 110/128 [00:01<00:00, 59.25it/s, loss=25.2, v_num=0]\u001b[A\n",
      "Epoch 57: 100%|███████████| 128/128 [00:02<00:00, 63.86it/s, loss=25.2, v_num=0]\u001b[A\n",
      "Epoch 58:  75%|█████████   | 96/128 [00:02<00:00, 44.24it/s, loss=24.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  86%|█████████▍ | 110/128 [00:02<00:00, 47.86it/s, loss=24.5, v_num=0]\u001b[A\n",
      "Epoch 58: 100%|███████████| 128/128 [00:02<00:00, 52.50it/s, loss=24.5, v_num=0]\u001b[A\n",
      "Epoch 59:  75%|█████████   | 96/128 [00:02<00:00, 46.96it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  86%|█████████▍ | 110/128 [00:02<00:00, 48.61it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▌                 | 14/32 [00:00<00:00, 63.34it/s]\u001b[A\n",
      "Epoch 59: 100%|███████████| 128/128 [00:02<00:00, 51.58it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Epoch 60:  75%|█████████   | 96/128 [00:02<00:00, 47.07it/s, loss=24.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 60:  86%|█████████▍ | 110/128 [00:02<00:00, 52.11it/s, loss=24.7, v_num=0]\u001b[A\n",
      "Epoch 60: 100%|███████████| 128/128 [00:02<00:00, 57.62it/s, loss=24.7, v_num=0]\u001b[A\n",
      "Epoch 61:  75%|█████████   | 96/128 [00:01<00:00, 60.66it/s, loss=24.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 61:  86%|█████████▍ | 110/128 [00:01<00:00, 66.51it/s, loss=24.8, v_num=0]\u001b[A\n",
      "Epoch 61: 100%|███████████| 128/128 [00:01<00:00, 68.64it/s, loss=24.8, v_num=0]\u001b[A\n",
      "Epoch 62:  75%|█████████   | 96/128 [00:01<00:00, 87.85it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 62:  86%|█████████▍ | 110/128 [00:01<00:00, 94.80it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Epoch 62: 100%|██████████| 128/128 [00:01<00:00, 102.76it/s, loss=26.5, v_num=0]\u001b[A\n",
      "Epoch 63:  75%|█████████   | 96/128 [00:01<00:00, 69.47it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 63:  86%|█████████▍ | 110/128 [00:01<00:00, 75.10it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Validating:  50%|███████████████               | 16/32 [00:00<00:00, 148.13it/s]\u001b[A\n",
      "Epoch 63: 100%|███████████| 128/128 [00:01<00:00, 77.12it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Epoch 64:  75%|█████████   | 96/128 [00:02<00:00, 44.98it/s, loss=24.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  86%|█████████▍ | 110/128 [00:02<00:00, 48.97it/s, loss=24.2, v_num=0]\u001b[A\n",
      "Epoch 64: 100%|███████████| 128/128 [00:02<00:00, 52.24it/s, loss=24.2, v_num=0]\u001b[A\n",
      "Epoch 65:  75%|█████████   | 96/128 [00:01<00:00, 68.22it/s, loss=23.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 65:  86%|█████████▍ | 110/128 [00:01<00:00, 74.81it/s, loss=23.8, v_num=0]\u001b[A\n",
      "Epoch 65: 100%|███████████| 128/128 [00:01<00:00, 80.48it/s, loss=23.8, v_num=0]\u001b[A\n",
      "Epoch 66:  75%|█████████   | 96/128 [00:01<00:00, 77.51it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 66:  86%|█████████▍ | 110/128 [00:01<00:00, 84.40it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Epoch 66: 100%|███████████| 128/128 [00:01<00:00, 90.55it/s, loss=23.9, v_num=0]\u001b[A\n",
      "Epoch 67:  75%|█████████   | 96/128 [00:01<00:00, 85.71it/s, loss=23.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 67:  86%|█████████▍ | 110/128 [00:01<00:00, 92.48it/s, loss=23.4, v_num=0]\u001b[A\n",
      "Epoch 67: 100%|███████████| 128/128 [00:01<00:00, 97.59it/s, loss=23.4, v_num=0]\u001b[A\n",
      "Epoch 68:  75%|█████████   | 96/128 [00:01<00:00, 92.03it/s, loss=22.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 68:  86%|█████████▍ | 110/128 [00:01<00:00, 99.52it/s, loss=22.8, v_num=0]\u001b[A\n",
      "Epoch 68: 100%|██████████| 128/128 [00:01<00:00, 106.08it/s, loss=22.8, v_num=0]\u001b[A\n",
      "Epoch 69:  75%|█████████   | 96/128 [00:01<00:00, 94.38it/s, loss=22.9, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 69:  86%|████████▌ | 110/128 [00:01<00:00, 102.68it/s, loss=22.9, v_num=0]\u001b[A\n",
      "Epoch 69: 100%|██████████| 128/128 [00:01<00:00, 105.55it/s, loss=22.9, v_num=0]\u001b[A\n",
      "Epoch 70:  75%|█████████   | 96/128 [00:01<00:00, 94.41it/s, loss=22.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 70:  86%|████████▌ | 110/128 [00:01<00:00, 102.47it/s, loss=22.7, v_num=0]\u001b[A\n",
      "Epoch 70: 100%|██████████| 128/128 [00:01<00:00, 108.52it/s, loss=22.7, v_num=0]\u001b[A\n",
      "Epoch 71:  75%|█████████   | 96/128 [00:01<00:00, 78.42it/s, loss=22.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 71:  86%|█████████▍ | 110/128 [00:01<00:00, 84.99it/s, loss=22.2, v_num=0]\u001b[A\n",
      "Epoch 71: 100%|███████████| 128/128 [00:01<00:00, 89.41it/s, loss=22.2, v_num=0]\u001b[A\n",
      "Epoch 72:  75%|█████████   | 96/128 [00:01<00:00, 48.30it/s, loss=22.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 72:  86%|█████████▍ | 110/128 [00:02<00:00, 53.19it/s, loss=22.5, v_num=0]\u001b[A\n",
      "Epoch 72: 100%|███████████| 128/128 [00:02<00:00, 58.41it/s, loss=22.5, v_num=0]\u001b[A\n",
      "Epoch 73:  75%|█████████   | 96/128 [00:01<00:00, 87.44it/s, loss=21.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 73:  86%|█████████▍ | 110/128 [00:01<00:00, 94.14it/s, loss=21.5, v_num=0]\u001b[A\n",
      "Epoch 73: 100%|███████████| 128/128 [00:01<00:00, 97.75it/s, loss=21.5, v_num=0]\u001b[A\n",
      "Epoch 74:  75%|█████████   | 96/128 [00:01<00:00, 85.19it/s, loss=21.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 74:  86%|█████████▍ | 110/128 [00:01<00:00, 92.41it/s, loss=21.7, v_num=0]\u001b[A\n",
      "Epoch 74: 100%|███████████| 128/128 [00:01<00:00, 96.34it/s, loss=21.7, v_num=0]\u001b[A\n",
      "Epoch 75:  75%|█████████   | 96/128 [00:01<00:00, 78.76it/s, loss=22.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 75:  86%|█████████▍ | 110/128 [00:01<00:00, 85.44it/s, loss=22.1, v_num=0]\u001b[A\n",
      "Epoch 75: 100%|███████████| 128/128 [00:01<00:00, 90.31it/s, loss=22.1, v_num=0]\u001b[A\n",
      "Epoch 76:  75%|██████████▌   | 96/128 [00:01<00:00, 72.47it/s, loss=22, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 76:  86%|███████████▏ | 110/128 [00:01<00:00, 77.96it/s, loss=22, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 136.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|█████████████| 128/128 [00:01<00:00, 82.67it/s, loss=22, v_num=0]\u001b[A\n",
      "Epoch 77:  75%|█████████   | 96/128 [00:01<00:00, 71.82it/s, loss=21.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 77:  86%|█████████▍ | 110/128 [00:01<00:00, 77.41it/s, loss=21.2, v_num=0]\u001b[A\n",
      "Epoch 77: 100%|███████████| 128/128 [00:01<00:00, 83.38it/s, loss=21.2, v_num=0]\u001b[A\n",
      "Epoch 78:  75%|██████████▌   | 96/128 [00:01<00:00, 84.63it/s, loss=21, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 78:  86%|███████████▏ | 110/128 [00:01<00:00, 90.57it/s, loss=21, v_num=0]\u001b[A\n",
      "Epoch 78: 100%|█████████████| 128/128 [00:01<00:00, 96.32it/s, loss=21, v_num=0]\u001b[A\n",
      "Epoch 79:  75%|█████████   | 96/128 [00:01<00:00, 83.28it/s, loss=20.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  86%|█████████▍ | 110/128 [00:01<00:00, 86.75it/s, loss=20.4, v_num=0]\u001b[A\n",
      "Epoch 79: 100%|███████████| 128/128 [00:01<00:00, 92.21it/s, loss=20.4, v_num=0]\u001b[A\n",
      "Epoch 80:  75%|█████████   | 96/128 [00:01<00:00, 85.77it/s, loss=20.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 80:  86%|█████████▍ | 110/128 [00:01<00:00, 93.56it/s, loss=20.2, v_num=0]\u001b[A\n",
      "Epoch 80: 100%|██████████| 128/128 [00:01<00:00, 100.90it/s, loss=20.2, v_num=0]\u001b[A\n",
      "Epoch 81:  75%|█████████   | 96/128 [00:01<00:00, 84.10it/s, loss=20.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 81:  86%|█████████▍ | 110/128 [00:01<00:00, 89.63it/s, loss=20.3, v_num=0]\u001b[A\n",
      "Epoch 81: 100%|███████████| 128/128 [00:01<00:00, 96.29it/s, loss=20.3, v_num=0]\u001b[A\n",
      "Epoch 82:  75%|█████████   | 96/128 [00:01<00:00, 95.67it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 82:  86%|████████▌ | 110/128 [00:01<00:00, 102.79it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Epoch 82: 100%|██████████| 128/128 [00:01<00:00, 108.62it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Epoch 83:  75%|█████████   | 96/128 [00:01<00:00, 93.15it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 83:  86%|████████▌ | 110/128 [00:01<00:00, 101.47it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Epoch 83: 100%|██████████| 128/128 [00:01<00:00, 108.16it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Epoch 84:  75%|█████████   | 96/128 [00:01<00:00, 91.85it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 84:  86%|█████████▍ | 110/128 [00:01<00:00, 99.40it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Epoch 84: 100%|██████████| 128/128 [00:01<00:00, 104.88it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Epoch 85:  75%|█████████   | 96/128 [00:01<00:00, 69.93it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 85:  86%|█████████▍ | 110/128 [00:01<00:00, 76.90it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Epoch 85: 100%|███████████| 128/128 [00:01<00:00, 83.98it/s, loss=20.5, v_num=0]\u001b[A\n",
      "Epoch 86:  75%|█████████   | 96/128 [00:01<00:00, 68.78it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 86:  86%|█████████▍ | 110/128 [00:01<00:00, 73.81it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 130.29it/s]\u001b[A\n",
      "Epoch 86: 100%|███████████| 128/128 [00:01<00:00, 78.04it/s, loss=19.4, v_num=0]\u001b[A\n",
      "Epoch 87:  75%|█████████   | 96/128 [00:01<00:00, 67.45it/s, loss=19.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  86%|█████████▍ | 110/128 [00:01<00:00, 71.17it/s, loss=19.3, v_num=0]\u001b[A\n",
      "Epoch 87: 100%|███████████| 128/128 [00:01<00:00, 76.99it/s, loss=19.3, v_num=0]\u001b[A\n",
      "Epoch 88:  75%|█████████   | 96/128 [00:01<00:00, 74.56it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                        | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  86%|█████████▍ | 110/128 [00:01<00:00, 78.56it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Epoch 88: 100%|███████████| 128/128 [00:01<00:00, 81.64it/s, loss=19.5, v_num=0]\u001b[A\n",
      "Epoch 89:  75%|██████████▌   | 96/128 [00:01<00:00, 74.65it/s, loss=19, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 89:  86%|███████████▏ | 110/128 [00:01<00:00, 80.91it/s, loss=19, v_num=0]\u001b[A\n",
      "Epoch 89: 100%|█████████████| 128/128 [00:01<00:00, 86.22it/s, loss=19, v_num=0]\u001b[A\n",
      "Epoch 90:  75%|█████████   | 96/128 [00:01<00:00, 77.12it/s, loss=18.7, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 90:  86%|█████████▍ | 110/128 [00:01<00:00, 83.09it/s, loss=18.7, v_num=0]\u001b[A\n",
      "Epoch 90: 100%|███████████| 128/128 [00:01<00:00, 88.55it/s, loss=18.7, v_num=0]\u001b[A\n",
      "Epoch 91:  75%|██████████▌   | 96/128 [00:01<00:00, 70.49it/s, loss=19, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 91:  86%|███████████▏ | 110/128 [00:01<00:00, 76.78it/s, loss=19, v_num=0]\u001b[A\n",
      "Epoch 91: 100%|█████████████| 128/128 [00:01<00:00, 81.74it/s, loss=19, v_num=0]\u001b[A\n",
      "Epoch 92:  75%|█████████   | 96/128 [00:01<00:00, 61.63it/s, loss=19.1, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 92:  86%|█████████▍ | 110/128 [00:01<00:00, 67.02it/s, loss=19.1, v_num=0]\u001b[A\n",
      "Epoch 92: 100%|███████████| 128/128 [00:01<00:00, 72.65it/s, loss=19.1, v_num=0]\u001b[A\n",
      "Epoch 93:  75%|█████████   | 96/128 [00:02<00:00, 45.54it/s, loss=18.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 93:  86%|█████████▍ | 110/128 [00:02<00:00, 50.10it/s, loss=18.2, v_num=0]\u001b[A\n",
      "Epoch 93: 100%|███████████| 128/128 [00:02<00:00, 55.22it/s, loss=18.2, v_num=0]\u001b[A\n",
      "Epoch 94:  75%|██████████▌   | 96/128 [00:01<00:00, 71.94it/s, loss=18, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 94:  86%|███████████▏ | 110/128 [00:01<00:00, 76.86it/s, loss=18, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 126.90it/s]\u001b[A\n",
      "Epoch 94: 100%|█████████████| 128/128 [00:01<00:00, 82.23it/s, loss=18, v_num=0]\u001b[A\n",
      "Epoch 95:  75%|█████████   | 96/128 [00:01<00:00, 84.28it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 95:  86%|█████████▍ | 110/128 [00:01<00:00, 91.40it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Epoch 95: 100%|███████████| 128/128 [00:01<00:00, 97.29it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Epoch 96:  75%|█████████   | 96/128 [00:01<00:00, 78.91it/s, loss=17.6, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 96:  86%|█████████▍ | 110/128 [00:01<00:00, 84.30it/s, loss=17.6, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Epoch 96: 100%|███████████| 128/128 [00:01<00:00, 84.20it/s, loss=17.6, v_num=0]\u001b[A\n",
      "Epoch 97:  75%|█████████   | 96/128 [00:01<00:00, 77.02it/s, loss=17.2, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 97:  86%|█████████▍ | 110/128 [00:01<00:00, 83.74it/s, loss=17.2, v_num=0]\u001b[A\n",
      "Epoch 97: 100%|███████████| 128/128 [00:01<00:00, 88.74it/s, loss=17.2, v_num=0]\u001b[A\n",
      "Epoch 98:  75%|█████████   | 96/128 [00:01<00:00, 78.85it/s, loss=17.3, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 98:  86%|█████████▍ | 110/128 [00:01<00:00, 85.68it/s, loss=17.3, v_num=0]\u001b[A\n",
      "Epoch 98: 100%|███████████| 128/128 [00:01<00:00, 91.48it/s, loss=17.3, v_num=0]\u001b[A\n",
      "Epoch 99:  75%|█████████   | 96/128 [00:01<00:00, 64.84it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 99:  86%|█████████▍ | 110/128 [00:01<00:00, 70.85it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Validating:  44%|█████████████▏                | 14/32 [00:00<00:00, 139.01it/s]\u001b[A\n",
      "Epoch 99: 100%|███████████| 128/128 [00:01<00:00, 75.20it/s, loss=17.8, v_num=0]\u001b[A\n",
      "Epoch 99: 100%|███████████| 128/128 [00:01<00:00, 74.90it/s, loss=17.8, v_num=0]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauren/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing:  88%|████████████████████████████▉    | 28/32 [00:00<00:00, 135.46it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|█████████████████████████████████| 32/32 [00:00<00:00, 138.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(1)\n",
    "\n",
    "csv_logger = CSVLogger('./', name='lstm', version='0'),\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=p['max_epochs'],\n",
    "    logger=csv_logger,\n",
    "    progress_bar_refresh_rate=2,\n",
    ")\n",
    "\n",
    "model = LSTMRegressor(\n",
    "    n_features = p['n_features'],\n",
    "    hidden_size = p['hidden_size'],\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size'],\n",
    "    criterion = p['criterion'],\n",
    "    num_layers = p['num_layers'],\n",
    "    dropout = p['dropout'],\n",
    "    learning_rate = p['learning_rate']\n",
    ")\n",
    "\n",
    "dm = ParticleAcceleratorDataModule(\n",
    "    seq_len = p['seq_len'],\n",
    "    batch_size = p['batch_size']\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "trainer.fit(model, dm)\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6d7d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './lstm/0/metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./lstm/0/metrics.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m metrics[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      3\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m metrics[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/mambaforge/envs/pytorch_env/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './lstm/0/metrics.csv'"
     ]
    }
   ],
   "source": [
    "metrics = pd.read_csv('./lstm/0/metrics.csv')\n",
    "train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
    "val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
    "test_loss = metrics['test_loss'].iloc[-1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
    "axes[0].set_title('Train loss per batch')\n",
    "axes[0].plot(train_loss['step'], train_loss['train_loss'])\n",
    "axes[1].set_title('Validation loss per epoch')\n",
    "axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
    "plt.show(block = True)\n",
    "\n",
    "print('MSE:')\n",
    "print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
    "print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.3f}\")\n",
    "print(f'Test loss:  {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da040eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
